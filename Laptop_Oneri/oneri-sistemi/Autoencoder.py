import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from tensorflow.keras.models import Model  # type: ignore
from tensorflow.keras.layers import Input, Dense  # type: ignore
from tensorflow.keras.optimizers import Adam  # type: ignore
import matplotlib.pyplot as plt

  #========================(CSV'yi oku)========================================================
DATA_PATH = "./oneri-sistemi/tamveriseti.csv"
raw_df = pd.read_csv(DATA_PATH)

  #========================(Primary Column'larÄ± elemeye sokma (tam dolu))========================================================
to_drop = ['Urun_Ad', 'Seri', 'Urun_URL']
df = raw_df.drop(columns=to_drop, errors='ignore')

#========================(Fiyat deÄŸerlerini numeric yapmak iÃ§in iÅŸlemler)========================================================

if 'Fiyat' in df.columns:
    df['Fiyat'] = (
        df['Fiyat']
        .astype(str)
        .str.replace('.', '', regex=False)
        .str.replace(',', '.', regex=False)
    )
    df['Fiyat'] = pd.to_numeric(df['Fiyat'], errors='coerce')
#========================(AÄŸÄ±rlÄ±k deÄŸerlerini numeric yapmak iÃ§in iÅŸlemler)========================================================

if 'Agirlik' in df.columns:
    df['Agirlik'] = pd.to_numeric(df['Agirlik'], errors='coerce')

#========================(En Ã§ok araÅŸtÄ±rÄ±lan column'larÄ± elemeye hazÄ±rla)========================================================
important_cols = ['Marka', 'SSD', 'Ekran_Karti_Hafizasi', 'RAM',
                  'Ekran_Boyutu', 'Isletim_Sistemi', 'Agirlik', 'Ekran_Karti_Modeli']
df = df.dropna(subset=important_cols, axis=0) #nulleri sil

#========================(Stringleri (object) kategorik, sayÄ±sal deÄŸerleri numeric tutalÄ±m)========================================================
categorical_cols = df.select_dtypes(include='object').columns.tolist()
numeric_cols = df.select_dtypes(include='number').columns.tolist()

#========================(One Hot Encoder'Ä±n KategÃ¶rik (SÃ¶zel) veriler iÃ§in Ã§aÄŸrÄ±lmasÄ±)========================================================
encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
encoded = encoder.fit_transform(df[categorical_cols])
#========================(MinMax'Ä±n Numerik veriler iÃ§in Ã§aÄŸrÄ±lmasÄ±)========================================================
scaler = MinMaxScaler()
scaled = scaler.fit_transform(df[numeric_cols])

#========================(CSV FormatÄ± iÃ§in tÃ¼m verileri birleÅŸtir)========================================================
X = np.concatenate([encoded, scaled], axis=1)

#========================(Null deÄŸer ne olursa olsun 0.0 dÃ¶nsÃ¼n)========================================================
X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)

#========================(Train Test verilerini ayÄ±r)========================================================
X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)

#========================(Auto Encoder'Ä± ayarla)========================================================
input_dim = X.shape[1] 
input_layer = Input(shape=(input_dim,)) #Feature TanÄ±mÄ± 
encoded = Dense(64, activation='relu')(input_layer) #64 NÃ¶ron relu modeli ile GiriÅŸ katmanÄ±
encoded = Dense(32, activation='relu')(encoded) #32 nÃ¶ron ara katman relu modeli
decoded = Dense(64, activation='relu')(encoded) #64 nÃ¶ron ara katman relu modeli
output_layer = Dense(input_dim, activation='sigmoid')(decoded) #Sigmoid kullan ve Ã§Ä±kÄ±ÅŸ ver

autoencoder = Model(inputs=input_layer, outputs=output_layer) #Girdi ve Ã‡Ä±ktÄ±
autoencoder.compile(optimizer=Adam(1e-3), loss='mse') # Adam optimizerÄ±nÄ± kullan hiperparametre iÃ§in en uygun deÄŸer ayrÄ±ca girildi ayrÄ±ca kayÄ±pÄ± gÃ¶ster

#========================(Model EÄŸitimini tamamla)========================================================
history = autoencoder.fit(
    X_train, X_train,
    epochs=50, # epoch sayÄ±sÄ±
    batch_size=16, #Mini batch sayÄ±sÄ±
    shuffle=True, #Verileri karÄ±ÅŸtÄ±r ki overfitting olmasÄ±n
    validation_data=(X_test, X_test) #DoÄŸrula
)

#========================(Grafik Ã‡iz)========================================================
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Autoencoder EÄŸitim SÃ¼reci')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("autoencoder_loss_plot.png") 
plt.show()

#========================(Train Test verilerini ayÄ±r)========================================================
encoder_model = Model(inputs=input_layer, outputs=encoded)
latent_vectors = encoder_model.predict(X)

#========================(Latent vektÃ¶rler ekle ve uygula)========================================================
latent_df = pd.DataFrame(latent_vectors, index=df.index)
final_df = pd.concat([raw_df.loc[df.index].reset_index(drop=True), latent_df.reset_index(drop=True)], axis=1)

#========================(Sonucu kaydet ve bitir)========================================================
final_df.to_csv("./oneri-sistemi/latent_vektorlu_laptoplar.csv", index=False)

print(f"âœ… EÄŸitim tamamlandÄ±. SonuÃ§ dosyasÄ±: latent_vektorlu_laptoplar.csv")
print(f"ğŸ“Š EÄŸitim grafiÄŸi: autoencoder_loss_plot.png")
